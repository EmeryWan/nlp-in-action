---
title: 6️⃣ 自动文本生成
order: 7
toc: menu
---

```jsx
/**
 * inline: true
 */
import React from 'react';
import { Image } from 'antd';
import { trueImgSrc } from 'nlp-in-action/utils';

export default () => {
  const path = '/img/banner_small.png';
  const truePath = trueImgSrc(path);
  return (
    <div className="post-top-icon">
      <Image
        src={truePath}
        preview={false}
      />
    </div>
  );
};
```


本节介绍一个神经网络的应用：文本生成 `Text Generation`。我们可以训练一个 `RNN` 并用它来自动生成文本，

生成的文本就像是人书写的一样，如果是用莎士比亚的书来训练 `RNN`，`RNN` 就会生成莎士比亚风格的语言；如果用 `Linux` 源代码来训练 `RNN`，`RNN` 就能学会写 `C语言`，虽然写出来的东西编译无法通过。


## 技术原理

接下来举个例子 🌰 来解释文本生成。

假设当前有这样的半句话：`the cat set on the ma`，我们想要预测这半句话的下一个字符是什么。我们可以利用 `RNN` 训练一个神经网络来预测下一个字符。


训练这个神经网络的数据是很多文本。首先我们我们要像之前小节所叙述的内容一样，进行文本处理，把文本分割成字符，并用 `one-hot encoding` 来表示字符。这样一来，每个字符就表示成一个 `one-hot` 向量。

接下把这些 `one-hot` 向量依次输入神经网络，`RNN` 的状态向量 $h$ 会积累看到的信息，返回最后一个状态向量 $h$ （包含了前面所有的信息）。

在 `RNN` 层的上面是一个 $softmax$ 分类器，把 $h$ 与参数矩阵 $w$ 相乘，得到一个向量，经过 $softmax$ 函数的变换，最终输出也是一个向量（这里省略参数 $b$）。

这个向量的每个元素都在 `0` 和 `1` 之间，元素全加起来等于 `1`。$softmax$ 分类器的输出，其实是一个概率分布。


现在我们假设这个神经网络已经训练好了，我们把 `the cat set on the ma`，输入这个神经网络，神经网络最上层的 $softmax$ 分类器，会输出这些概率值。

我们来看一下这些概率值，每个字符对应一个概率值，其中概率最大的是字符 `t`，概率值大约是 `0.175`，有了这些概率值，我们就可以预测下一个字符了。

我们获得了概率值之后，可以选概率最大的字符 `t`，也可以按照概率值做随机抽样。

假设我们抽到了字符 `t`，然后就把 `t` 接到输入的文本末尾得到 `the cat set on the mat`。然后把 `the cat set on the mat` 这句话作为输入，计算下一个字符的概率分布，从而生成下一个字符。

可能下一轮抽到的字符会是句号 `.`。生成的这句话就成了：`the cat set on the mat.`，

再重复这个过程，下一次可能会抽到空格 ` `，再下次可能会抽到一个字母，不停重复下去可以生成一段话，一篇文章，甚至是一本书。


## 具体步骤



## 总结

总结一下这节课的内容，如果我们想要利用神经网络生成文本，首先需要训练一个循环神经网络。

第一步是把训练文本划分成很多个片段 `segments`，`segment` 是神经网络的输入，下一个字符 `next character` 是标签，作为神经网络的输出。

文本被划分成了很多 `segment` 和 `next character` 的二元组，作为这个神经网络的训练数据。


第二步是对字符做 `one-hot encoding`，把字符编码成向量，每个字符都用 $v*1$ 向量来表示。$v$ 是 `vocabulary`，是字典的长度，即不同字符的数量。

每个文本片段 `segment`，都用一个 $l*v$ 的矩阵来表示，$l$ 是每个文本片段的长度，每个文本片段有 $l$ 个字符。


第三步是搭一个神经网络，输入层是文本片段表示成 $l*v$ 的矩阵，然后是 `LSTM` 层和全连接层，全连接层用 $softmax$ 激活函数。输出的是一个 $v*1$ 向量，向量的每一个元素是一个字符的概率。

最后用准备好的数据来训练神经网络，训练几十个 `epochs`。训练完成后，神经网络就可以用神经网络来生成文本。

利用这个神经网络生成文本，首先我们需要自己写点什么，作为种子 `seed`（神经网络的初始值），然后神经网络会根据这些输入来生成文本。


之后重复下面这几步，每一轮能生成一个字符：

- 将文本片段做 `one-hot encoding`，输入神经网络；
- 神经网络输出一个向量，向量每个元素都是一个字符的概率值，根据这些概率值做抽样，得到下一个字符；
- 把新生成的字符接到片段的后面，作为神经网络新的输入，开始下一轮循环；

直到神经网络生成终止符，即完成一次文本生成。
